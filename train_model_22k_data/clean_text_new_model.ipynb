{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model on 22k Allsides Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean/Prep/Zip Merge AllSides Data\n",
    "\n",
    "Create train/validate/test datasets\n",
    "train_ratio = 0.8\n",
    "val_ratio   = 0.1\n",
    "test_ratio  = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Created train.csv, val.csv, test.csv (with minimal cleaning).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "import unicodedata\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from ftfy import fix_text\n",
    "\n",
    "# -------------- Minimal Cleaning Function -------------- #\n",
    "def minimal_clean(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Minimal cleaning for training data:\n",
    "      - Normalizes unicode (NFKC) to handle odd characters \n",
    "      - Removes control characters\n",
    "      - Replaces consecutive whitespace with a single space\n",
    "      - Retains punctuation (including quotes)\n",
    "    \"\"\"\n",
    "    # 1) First, fix text encoding issues (mojibake)\n",
    "    text = fix_text(text)\n",
    "\n",
    "    # 2) Normalize unicode (NFKC) to handle half-width forms, etc.\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # 3) Remove control chars (but keep punctuation)\n",
    "    text = re.sub(r\"[\\x00-\\x1F\\x7F]\", \"\", text)\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "\n",
    "    # 4) Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n",
    "# Paths to your label folders\n",
    "DATA_DIR = \"/Users/bryce/Desktop/INLS697/INLS697_proj/allsides_data\"\n",
    "LEFT_DIR = os.path.join(DATA_DIR, \"left\")\n",
    "CENTER_DIR = os.path.join(DATA_DIR, \"center\")\n",
    "RIGHT_DIR = os.path.join(DATA_DIR, \"right\")\n",
    "\n",
    "# Where we'll save our output CSV files\n",
    "TRAIN_CSV = \"train.csv\"\n",
    "VAL_CSV   = \"val.csv\"\n",
    "TEST_CSV  = \"test.csv\"\n",
    "\n",
    "# Train/Val/Test split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio   = 0.1\n",
    "test_ratio  = 0.1\n",
    "\n",
    "def get_filepaths_and_labels(folder_path, label):\n",
    "    \"\"\"\n",
    "    Returns a list of (filepath, label) for all .txt files in folder_path.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            files.append((full_path, label))\n",
    "    return files\n",
    "\n",
    "# Collect filepaths from each label folder\n",
    "left_files   = get_filepaths_and_labels(LEFT_DIR, \"left\")\n",
    "center_files = get_filepaths_and_labels(CENTER_DIR, \"center\")\n",
    "right_files  = get_filepaths_and_labels(RIGHT_DIR, \"right\")\n",
    "\n",
    "# Combine into one list\n",
    "all_files = left_files + center_files + right_files\n",
    "\n",
    "# Shuffle to randomize\n",
    "random.shuffle(all_files)\n",
    "\n",
    "# We'll create separate arrays for each label,\n",
    "# to ensure we do a label-stratified split.\n",
    "label_map = defaultdict(list)\n",
    "for filepath, label in all_files:\n",
    "    label_map[label].append(filepath)\n",
    "\n",
    "# Now do a split for each label\n",
    "train_data = []\n",
    "val_data   = []\n",
    "test_data  = []\n",
    "\n",
    "for label, paths in label_map.items():\n",
    "    random.shuffle(paths)\n",
    "    total_count = len(paths)\n",
    "    train_end  = int(total_count * train_ratio)\n",
    "    val_end    = int(total_count * (train_ratio + val_ratio))\n",
    "\n",
    "    train_paths = paths[:train_end]\n",
    "    val_paths   = paths[train_end:val_end]\n",
    "    test_paths  = paths[val_end:]\n",
    "\n",
    "    # Read text from each path, clean, and store (text, label)\n",
    "    for p in train_paths:\n",
    "        with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            raw_text = f.read()\n",
    "        cleaned_text = minimal_clean(raw_text)\n",
    "        train_data.append((cleaned_text, label))\n",
    "\n",
    "    for p in val_paths:\n",
    "        with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            raw_text = f.read()\n",
    "        cleaned_text = minimal_clean(raw_text)\n",
    "        val_data.append((cleaned_text, label))\n",
    "\n",
    "    for p in test_paths:\n",
    "        with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            raw_text = f.read()\n",
    "        cleaned_text = minimal_clean(raw_text)\n",
    "        test_data.append((cleaned_text, label))\n",
    "\n",
    "# Shuffle each split again (to ensure randomness across labels)\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(val_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "def write_to_csv(data, out_csv):\n",
    "    with open(out_csv, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"text\", \"label\"])  # CSV header\n",
    "        for (text, label) in data:\n",
    "            writer.writerow([text, label])\n",
    "\n",
    "# Finally, write out your train, val, test CSVs\n",
    "write_to_csv(train_data, TRAIN_CSV)\n",
    "write_to_csv(val_data,   VAL_CSV)\n",
    "write_to_csv(test_data,  TEST_CSV)\n",
    "\n",
    "print(\"Done! Created train.csv, val.csv, test.csv (with minimal cleaning).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
