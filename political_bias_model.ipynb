{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API calls for TikTok\n",
    "\n",
    "(disregard, did not work)\n",
    "\n",
    "docs: https://github.com/davidteather/TikTok-Api & https://davidteather.github.io/TikTok-Api/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiktokapipy.api import TikTokAPI\n",
    "\n",
    "def do_something():\n",
    "    with TikTokAPI() as api:\n",
    "        challenge = api.challenge(\"climate_change\")\n",
    "        for video in challenge.videos:\n",
    "            return video_link()\n",
    "\n",
    "print(do_something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function test_sort_challenge_videos at 0x10a039000>\n"
     ]
    }
   ],
   "source": [
    "def test_sort_challenge_videos(sync_api, challenge_name):\n",
    "    challenge = sync_api.challenge(challenge_name)\n",
    "    most_recent = -1\n",
    "    for video in challenge.videos.sorted_by(\n",
    "        lambda vid: vid.stats.play_count\n",
    "    ).light_models:\n",
    "        assert video.stats.play_count >= most_recent\n",
    "        most_recent = video.stats.play_count\n",
    "\n",
    "print(test_sort_challenge_videos(, \"climate_change\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiktokapipy.api import TikTokAPI\n",
    "\n",
    "async def scrape_captions_from_challenge(challenge_name):\n",
    "    async with TikTokAPI() as bot:\n",
    "        # Search for the challenge\n",
    "        challenge = await bot.search_challenge(challenge_name)\n",
    "\n",
    "        # Fetch videos from the challenge\n",
    "        videos = await bot.get_videos_by_challenge(challenge)\n",
    "\n",
    "        # Loop through videos and extract captions\n",
    "        for video in videos:\n",
    "            video_data = await bot.video(id=video.id)\n",
    "            subtitles = video_data.subtitle_data\n",
    "            for subtitle in subtitles:\n",
    "                print(subtitle.text)\n",
    "\n",
    "# Example challenge name\n",
    "challenge_name = 'climate_change'\n",
    "scrape_captions_from_challenge(challenge_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TikTokApi import TikTokAPI\n",
    "\n",
    "api = TikTokAPI()\n",
    "\n",
    "for video in api.trending.videos():\n",
    "    print(video.as_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GET request that relies on CSS selectors\n",
    "\n",
    "did not work because TikTok relies on javascript to load in the html, therefore without a program like selenium it won't work. API calls above essentially did that, so not work pursuing this method any longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element not found\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = 'https://www.tiktok.com/@davidpakmanshow/video/7221638603321953582'\n",
    "\n",
    "# Send an HTTP request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Use the CSS selector to find the desired content\n",
    "    # Adjust the selector as per the correct structure of your page\n",
    "    selector = '#main-content-video_detail > div > div.tiktok-12kupwv-DivContentContainer.ege8lhx2 > div.tiktok-1czmy9n-DivVideoList.ege8lhx5 > div:nth-child(1) > ul'\n",
    "    element = soup.select_one(selector)\n",
    "\n",
    "    if element:\n",
    "        # Process the element as needed, e.g., extract text, links, etc.\n",
    "        print(element.text)\n",
    "    else:\n",
    "        print(\"Element not found\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go green! We gotta make the planet clean. She'll be putting all the right stuff in the recycling bin. Is gonna counteract all of the fumes from the major corporations. Corporations? The fuck the corporations? Corporate. I did it again. All the major corporations. We'll cancel out all of the fumes from the major corporations. Stone cold facts about climate change is that every so often, the earth goes through a massive change completely naturally. Are humans contributing to it? Yes, probably. But not nearly as much as the government is making out. See, over time, the earth gets hotter, and then over time the earth gets colder. That's why we've had several ice ages. And it had absolutely fuck all to do with humans releasing CO2, I can tell you that. The question is, if it is the CO2 that's causing this massive issue, why is it that the little guy who uses almost nothing and still does all the right things for climate change is the one who ends up getting penalised for it? Your government are hoping to rule out things like 15 minutes city so that you can't travel too fast, so that you're not using as much fuel, which bullshit. They've introduced the sugar tax so that our people are more healthy. But then they're the ones that put the sugar in fucking everything. And then also on top of that, it's not gonna do anything apart from put money in the government's pockets. Just When they release the 5 p charge for the plastic bags, did that stop anyone from using plastic bags? No, we just put money in the government's pockets. And they do all this to the little man while completely ignoring the major corporations. I did it again, who are doing all of this. You think about Amazon, Netflix, Google. All these corporations using huge amounts of electricity, all for profit. Majority of them are just dumping it straight back into the ocean when they're done with it. The little guy like you and me who lives in the studio flat and doesn't drive and just only ever uses their fucking phone is apparently the reason why the entire earth is collapsing. And to be perfectly honest, if the overwhelming majority of the population believe all of this shit that's being spewed at us by the World Health Organization, then we deserve to be locked up in 15 minutes cities. Not gonna lie, you too stupid.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample transcript data\n",
    "data = \"Go green! We gotta make the planet clean. She'll be putting all the right stuff in the recycling bin. Is gonna counteract all of the fumes from the major corporations. Corporations? The fuck the corporations? Corporate. I did it again. All the major corporations. We'll cancel out all of the fumes from the major corporations. Stone cold facts about climate change is that every so often, the earth goes through a massive change completely naturally. Are humans contributing to it? Yes, probably. But not nearly as much as the government is making out. See, over time, the earth gets hotter, and then over time the earth gets colder. That's why we've had several ice ages. And it had absolutely fuck all to do with humans releasing CO2, I can tell you that. The question is, if it is the CO2 that's causing this massive issue, why is it that the little guy who uses almost nothing and still does all the right things for climate change is the one who ends up getting penalised for it? Your government are hoping to rule out things like 15 minutes city so that you can't travel too fast, so that you're not using as much fuel, which bullshit. They've introduced the sugar tax so that our people are more healthy. But then they're the ones that put the sugar in fucking everything. And then also on top of that, it's not gonna do anything apart from put money in the government's pockets. Just When they release the 5 p charge for the plastic bags, did that stop anyone from using plastic bags? No, we just put money in the government's pockets. And they do all this to the little man while completely ignoring the major corporations. I did it again, who are doing all of this. You think about Amazon, Netflix, Google. All these corporations using huge amounts of electricity, all for profit. Majority of them are just dumping it straight back into the ocean when they're done with it. The little guy like you and me who lives in the studio flat and doesn't drive and just only ever uses their fucking phone is apparently the reason why the entire earth is collapsing. And to be perfectly honest, if the overwhelming majority of the population believe all of this shit that's being spewed at us by the World Health Organization, then we deserve to be locked up in 15 minutes cities. Not gonna lie, you too stupid.\"\n",
    "\n",
    "\n",
    "\n",
    "# Regular expression to match timestamps\n",
    "timestamp_pattern = re.compile(r'\\d{2}:\\d{2}\\n?')\n",
    "\n",
    "# Remove timestamps using regex substitution\n",
    "cleaned_data = re.sub(timestamp_pattern, '', data)\n",
    "\n",
    "# Further cleanup if needed (e.g., extra whitespace, special characters)\n",
    "cleaned_data = cleaned_data.strip().replace('\\n', ' ')\n",
    "\n",
    "print(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Dataset!!\n",
    "\n",
    "See info here: https://huggingface.co/datasets/valurank/PoliticalBias_AllSides_Txt\n",
    "\n",
    "~20k articles labeled left, right, or center by the editors of allsides.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes the raw data from the allsides.com dataset and looks for references of 'climate change'. If present, it appends the content to a new data set which is either left/right and mentions climate change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7803/7803 files (100.00%)\n",
      "CSV file created: left_raw_output_w_count.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "# Function to append file content to CSV\n",
    "def append_to_csv(file_id, file_path, csv_writer):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        csv_writer.writerow([file_id, os.path.basename(file_path), \"left\", content])  # 0 is for political_label\n",
    "\n",
    "# Function to display progress\n",
    "def display_progress(current, total):\n",
    "    progress = (current / total) * 100\n",
    "    print(f'Processing {current}/{total} files ({progress:.2f}%)', end='\\r')\n",
    "\n",
    "# Directory containing the text files\n",
    "directory = '/Users/bryce/Downloads/AllSides/Left Data'\n",
    "\n",
    "# Path for the output CSV file\n",
    "output_csv = 'left_raw_output_w_count.csv'\n",
    "\n",
    "# List of files in the diectory\n",
    "files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "file_id = 0\n",
    "# Open the CSV file in write mode\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write header\n",
    "    writer.writerow(['id', 'file_name', 'political_label', 'content'])\n",
    "\n",
    "    # Process each file\n",
    "    for i, filename in enumerate(files):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Append file content to CSV\n",
    "        append_to_csv(file_id, file_path, writer)\n",
    "        file_id += 1\n",
    "        # Display progress\n",
    "        display_progress(i + 1, len(files))\n",
    "\n",
    "print(\"\\nCSV file created:\", output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function normalizes the dataset and combines into 1 dataset\n",
    "\n",
    "Of important note, because the dataset is filtered for the reference of \"climate change\" there is an imbalance of entries for left and right...\n",
    "left = 331\n",
    "right = 172\n",
    "This is partially remedied by adjusting the class weights to 'balanced' (this is done in the Word2Vec approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Normalize unicode characters\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Replace newlines and tabs with space\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "    # Remove punctuation and special characters (keep only letters and spaces)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Load the datasets\n",
    "left_df = pd.read_csv('left_raw_output_2.csv')\n",
    "right_df = pd.read_csv('right_raw_output_2.csv')\n",
    "# center_df = pd.read_csv('center_raw_output_2.csv')  # Uncomment and adjust path as necessary\n",
    "\n",
    "# Clean the content columns\n",
    "left_df['cleaned_content'] = left_df['content'].apply(clean_text)\n",
    "right_df['cleaned_content'] = right_df['content'].apply(clean_text)\n",
    "# center_df['cleaned_content'] = center_df['content'].apply(clean_text)\n",
    "\n",
    "# Drop the original 'content' column\n",
    "left_df = left_df.drop(columns=['content'])\n",
    "right_df = right_df.drop(columns=['content'])\n",
    "# center_df = center_df.drop(columns=['content'])  # Uncomment this line if using center_df\n",
    "\n",
    "# Combine the datasets\n",
    "combined_df = pd.concat([left_df, right_df], ignore_index=True)  # Add center_df to the list if using\n",
    "\n",
    "# Save the combined dataset\n",
    "combined_df.to_csv('combined_dataset_2-labels.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uses Logistic Regression and Tf-IDF (like hmw 3) to predict the odds of being classified as left or right\n",
    "\n",
    "use 2 labels left and right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7128712871287128\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        left       0.72      0.87      0.79        62\n",
      "       right       0.69      0.46      0.55        39\n",
      "\n",
      "    accuracy                           0.71       101\n",
      "   macro avg       0.71      0.67      0.67       101\n",
      "weighted avg       0.71      0.71      0.70       101\n",
      "\n",
      "Predicted probabilities:\n",
      " [[0.53774126 0.46225874]\n",
      " [0.62088276 0.37911724]\n",
      " [0.7462755  0.2537245 ]\n",
      " [0.54031503 0.45968497]\n",
      " [0.45982347 0.54017653]\n",
      " [0.58213597 0.41786403]\n",
      " [0.56305462 0.43694538]\n",
      " [0.6503989  0.3496011 ]\n",
      " [0.39920848 0.60079152]\n",
      " [0.41866039 0.58133961]\n",
      " [0.60093235 0.39906765]\n",
      " [0.5849814  0.4150186 ]\n",
      " [0.24356741 0.75643259]\n",
      " [0.89037341 0.10962659]\n",
      " [0.695849   0.304151  ]\n",
      " [0.74198712 0.25801288]\n",
      " [0.62495953 0.37504047]\n",
      " [0.5691392  0.4308608 ]\n",
      " [0.54402133 0.45597867]\n",
      " [0.59689579 0.40310421]\n",
      " [0.58094648 0.41905352]\n",
      " [0.50956567 0.49043433]\n",
      " [0.57429915 0.42570085]\n",
      " [0.53550461 0.46449539]\n",
      " [0.49943988 0.50056012]\n",
      " [0.48294752 0.51705248]\n",
      " [0.60071086 0.39928914]\n",
      " [0.51441756 0.48558244]\n",
      " [0.56443164 0.43556836]\n",
      " [0.44924344 0.55075656]\n",
      " [0.63097334 0.36902666]\n",
      " [0.45101574 0.54898426]\n",
      " [0.48114433 0.51885567]\n",
      " [0.51958503 0.48041497]\n",
      " [0.54996335 0.45003665]\n",
      " [0.62727422 0.37272578]\n",
      " [0.6024916  0.3975084 ]\n",
      " [0.48096326 0.51903674]\n",
      " [0.58292395 0.41707605]\n",
      " [0.74809195 0.25190805]\n",
      " [0.50837844 0.49162156]\n",
      " [0.58197424 0.41802576]\n",
      " [0.5753757  0.4246243 ]\n",
      " [0.59693217 0.40306783]\n",
      " [0.61090651 0.38909349]\n",
      " [0.60056528 0.39943472]\n",
      " [0.5237394  0.4762606 ]\n",
      " [0.57692866 0.42307134]\n",
      " [0.52635679 0.47364321]\n",
      " [0.42491391 0.57508609]\n",
      " [0.48839204 0.51160796]\n",
      " [0.54872931 0.45127069]\n",
      " [0.59152402 0.40847598]\n",
      " [0.61962122 0.38037878]\n",
      " [0.89037341 0.10962659]\n",
      " [0.47725247 0.52274753]\n",
      " [0.47924406 0.52075594]\n",
      " [0.49977313 0.50022687]\n",
      " [0.4666319  0.5333681 ]\n",
      " [0.58135339 0.41864661]\n",
      " [0.51956061 0.48043939]\n",
      " [0.6407945  0.3592055 ]\n",
      " [0.53872901 0.46127099]\n",
      " [0.61141408 0.38858592]\n",
      " [0.51717666 0.48282334]\n",
      " [0.66500096 0.33499904]\n",
      " [0.5726844  0.4273156 ]\n",
      " [0.60080521 0.39919479]\n",
      " [0.5138143  0.4861857 ]\n",
      " [0.46501906 0.53498094]\n",
      " [0.66220744 0.33779256]\n",
      " [0.52677667 0.47322333]\n",
      " [0.61043447 0.38956553]\n",
      " [0.52069093 0.47930907]\n",
      " [0.47492105 0.52507895]\n",
      " [0.45682507 0.54317493]\n",
      " [0.5835122  0.4164878 ]\n",
      " [0.54087301 0.45912699]\n",
      " [0.47314196 0.52685804]\n",
      " [0.576502   0.423498  ]\n",
      " [0.61399249 0.38600751]\n",
      " [0.55235572 0.44764428]\n",
      " [0.43523751 0.56476249]\n",
      " [0.52601169 0.47398831]\n",
      " [0.56906679 0.43093321]\n",
      " [0.4408009  0.5591991 ]\n",
      " [0.47578216 0.52421784]\n",
      " [0.56293018 0.43706982]\n",
      " [0.5663245  0.4336755 ]\n",
      " [0.52303611 0.47696389]\n",
      " [0.6343994  0.3656006 ]\n",
      " [0.40215873 0.59784127]\n",
      " [0.53852196 0.46147804]\n",
      " [0.52309168 0.47690832]\n",
      " [0.48574449 0.51425551]\n",
      " [0.57019025 0.42980975]\n",
      " [0.55212592 0.44787408]\n",
      " [0.50947841 0.49052159]\n",
      " [0.44583421 0.55416579]\n",
      " [0.55272718 0.44727282]\n",
      " [0.58383046 0.41616954]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib  # Import joblib for saving and loading models\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('/Users/bryce/Desktop/INLS697/INLS697_proj/combined_dataset_2-labels.csv')\n",
    "\n",
    "# Assume 'cleaned_content' is the feature and 'political_label' is the target variable\n",
    "X = df['cleaned_content']\n",
    "y = df['political_label']\n",
    "\n",
    "# Splitting the data into training and valid sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.85, min_df=3)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_valid_tfidf = vectorizer.transform(X_valid)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression(C = 1, class_weight='balanced')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(model, 'models/logistic_regression_model_2_labels.pkl')\n",
    "joblib.dump(vectorizer, 'models/tfidf_vectorizer_2_labels.pkl')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_valid_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_valid, y_pred))\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba = model.predict_proba(X_valid_tfidf)\n",
    "print(\"Predicted probabilities:\\n\", y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173     left\n",
      "274     left\n",
      "489    right\n",
      "72      left\n",
      "305     left\n",
      "       ...  \n",
      "331    right\n",
      "411    right\n",
      "502    right\n",
      "349    right\n",
      "86      left\n",
      "Name: political_label, Length: 101, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial: use 3 labels (left, right and center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      center       0.80      0.13      0.23        30\n",
      "        left       0.62      0.95      0.75        79\n",
      "       right       0.60      0.22      0.32        27\n",
      "\n",
      "    accuracy                           0.62       136\n",
      "   macro avg       0.67      0.43      0.43       136\n",
      "weighted avg       0.66      0.62      0.55       136\n",
      "\n",
      "Predicted probabilities:\n",
      " [[0.22027071 0.5004158  0.27931349]\n",
      " [0.15693906 0.69854433 0.14451661]\n",
      " [0.19109065 0.45892087 0.34998848]\n",
      " [0.28550768 0.40546214 0.30903017]\n",
      " [0.40171729 0.34012487 0.25815783]\n",
      " [0.29072206 0.47870174 0.2305762 ]\n",
      " [0.34447152 0.39001327 0.26551521]\n",
      " [0.25511944 0.50412558 0.24075498]\n",
      " [0.33044361 0.34864698 0.32090941]\n",
      " [0.20683282 0.2719198  0.52124738]\n",
      " [0.28398061 0.33820389 0.37781551]\n",
      " [0.21928558 0.38994417 0.39077026]\n",
      " [0.23786718 0.39893351 0.36319931]\n",
      " [0.30458905 0.4916008  0.20381015]\n",
      " [0.31505596 0.33534839 0.34959566]\n",
      " [0.27478157 0.50714178 0.21807666]\n",
      " [0.24129819 0.53886289 0.21983891]\n",
      " [0.26036084 0.46870985 0.27092931]\n",
      " [0.19210629 0.61214516 0.19574855]\n",
      " [0.25318994 0.4319892  0.31482085]\n",
      " [0.24809342 0.34439607 0.40751052]\n",
      " [0.19764425 0.53385621 0.26849954]\n",
      " [0.21974018 0.48066753 0.29959229]\n",
      " [0.29046862 0.39948499 0.31004639]\n",
      " [0.02785923 0.95010067 0.0220401 ]\n",
      " [0.32540923 0.40429958 0.27029119]\n",
      " [0.11438525 0.66888826 0.21672649]\n",
      " [0.27769436 0.54076363 0.18154201]\n",
      " [0.20134453 0.58596923 0.21268624]\n",
      " [0.46917688 0.24245487 0.28836825]\n",
      " [0.21466842 0.5819949  0.20333668]\n",
      " [0.20001436 0.59206374 0.20792189]\n",
      " [0.22450361 0.45995173 0.31554465]\n",
      " [0.30128846 0.42842572 0.27028581]\n",
      " [0.22032478 0.57363498 0.20604024]\n",
      " [0.3212115  0.43398784 0.24480066]\n",
      " [0.24445374 0.52015574 0.23539052]\n",
      " [0.20922347 0.58961795 0.20115857]\n",
      " [0.29347454 0.44889776 0.2576277 ]\n",
      " [0.17193206 0.66232242 0.16574552]\n",
      " [0.4077064  0.41154071 0.18075289]\n",
      " [0.2458697  0.54234473 0.21178557]\n",
      " [0.28899802 0.45972626 0.25127572]\n",
      " [0.1529049  0.62807333 0.21902177]\n",
      " [0.17652036 0.60661368 0.21686596]\n",
      " [0.24822825 0.47760301 0.27416874]\n",
      " [0.23046154 0.53018883 0.23934964]\n",
      " [0.24143467 0.4287302  0.32983514]\n",
      " [0.11077073 0.78926459 0.09996468]\n",
      " [0.23352865 0.45578852 0.31068283]\n",
      " [0.27894451 0.49831346 0.22274203]\n",
      " [0.30720668 0.46720075 0.22559257]\n",
      " [0.33203239 0.4082266  0.25974102]\n",
      " [0.19391348 0.53790159 0.26818493]\n",
      " [0.168628   0.64442709 0.1869449 ]\n",
      " [0.15855455 0.1971157  0.64432975]\n",
      " [0.21728663 0.50672861 0.27598476]\n",
      " [0.29951211 0.3863193  0.3141686 ]\n",
      " [0.18513824 0.55048836 0.2643734 ]\n",
      " [0.25635217 0.43426304 0.30938479]\n",
      " [0.34701961 0.39756488 0.25541551]\n",
      " [0.32158104 0.45477831 0.22364065]\n",
      " [0.24543675 0.50304657 0.25151668]\n",
      " [0.23855035 0.36872284 0.39272681]\n",
      " [0.18385064 0.63637512 0.17977424]\n",
      " [0.23339605 0.4213682  0.34523575]\n",
      " [0.3403686  0.36921971 0.29041169]\n",
      " [0.25781679 0.49955017 0.24263304]\n",
      " [0.32763114 0.43429358 0.23807528]\n",
      " [0.204447   0.60794802 0.18760499]\n",
      " [0.21238013 0.60132729 0.18629258]\n",
      " [0.24755332 0.47187556 0.28057112]\n",
      " [0.24305714 0.52384921 0.23309365]\n",
      " [0.23278827 0.4941344  0.27307733]\n",
      " [0.27555148 0.44793067 0.27651785]\n",
      " [0.25846651 0.5241669  0.21736659]\n",
      " [0.24931395 0.45349259 0.29719345]\n",
      " [0.20440604 0.53331042 0.26228354]\n",
      " [0.3584025  0.35730733 0.28429017]\n",
      " [0.22655718 0.5626447  0.21079812]\n",
      " [0.1558801  0.17324939 0.67087052]\n",
      " [0.19887826 0.5471638  0.25395794]\n",
      " [0.50767958 0.29275774 0.19956268]\n",
      " [0.21692406 0.47782227 0.30525367]\n",
      " [0.24877863 0.47233635 0.27888502]\n",
      " [0.29690219 0.35239482 0.35070299]\n",
      " [0.23120737 0.49048529 0.27830734]\n",
      " [0.30736231 0.50953555 0.18310214]\n",
      " [0.22996283 0.5427841  0.22725307]\n",
      " [0.19844961 0.43109696 0.37045343]\n",
      " [0.30301305 0.46448376 0.23250319]\n",
      " [0.20583202 0.57362265 0.22054533]\n",
      " [0.34243225 0.37054447 0.28702328]\n",
      " [0.24581285 0.49390092 0.26028624]\n",
      " [0.23171626 0.48425897 0.28402477]\n",
      " [0.36216401 0.44310019 0.1947358 ]\n",
      " [0.15955755 0.67766123 0.16278122]\n",
      " [0.26177748 0.46073896 0.27748355]\n",
      " [0.2318254  0.45233615 0.31583845]\n",
      " [0.1906369  0.62178621 0.18757689]\n",
      " [0.26042898 0.44519494 0.29437608]\n",
      " [0.23097865 0.53554233 0.23347901]\n",
      " [0.16736028 0.49967528 0.33296444]\n",
      " [0.23769291 0.47000276 0.29230433]\n",
      " [0.26220274 0.46746443 0.27033283]\n",
      " [0.23887366 0.55048028 0.21064606]\n",
      " [0.21527504 0.60721296 0.177512  ]\n",
      " [0.27560777 0.42666329 0.29772894]\n",
      " [0.32313186 0.48330109 0.19356705]\n",
      " [0.27774436 0.45422513 0.26803051]\n",
      " [0.40691684 0.2956495  0.29743366]\n",
      " [0.33471091 0.45395323 0.21133586]\n",
      " [0.23410497 0.54447686 0.22141817]\n",
      " [0.25142142 0.36729295 0.38128563]\n",
      " [0.24785218 0.53820574 0.21394209]\n",
      " [0.19130124 0.52317566 0.2855231 ]\n",
      " [0.23421914 0.57963897 0.18614189]\n",
      " [0.30807174 0.43548256 0.2564457 ]\n",
      " [0.31354288 0.38707632 0.2993808 ]\n",
      " [0.22458848 0.49834908 0.27706244]\n",
      " [0.33166587 0.395673   0.27266113]\n",
      " [0.20249664 0.59578232 0.20172105]\n",
      " [0.26549669 0.47588554 0.25861777]\n",
      " [0.08246909 0.84118615 0.07634476]\n",
      " [0.23294072 0.61065737 0.15640191]\n",
      " [0.31286759 0.29740072 0.38973169]\n",
      " [0.24041486 0.46793008 0.29165506]\n",
      " [0.13285719 0.68326282 0.18387999]\n",
      " [0.25576605 0.53581259 0.20842136]\n",
      " [0.29293925 0.41434894 0.29271181]\n",
      " [0.23714465 0.50424527 0.25861008]\n",
      " [0.15905452 0.60880535 0.23214013]\n",
      " [0.20638138 0.54086274 0.25275588]\n",
      " [0.25645031 0.49692037 0.24662932]\n",
      " [0.30253915 0.42182111 0.27563974]\n",
      " [0.22105811 0.54004334 0.23889855]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib  # Import joblib for saving and loading models\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('/Users/bryce/Desktop/INLS690/final_project/combined_dataset_3-labels.csv')\n",
    "\n",
    "# Assume 'cleaned_content' is the feature and 'political_label' is the target variable\n",
    "X = df['cleaned_content']\n",
    "y = df['political_label']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.85, min_df=3)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression(C = 1, multi_class='multinomial')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(model, '/Users/bryce/Desktop/INLS690/final_project/models/logistic_regression_model_3_labels.pkl')\n",
    "joblib.dump(vectorizer, '/Users/bryce/Desktop/INLS690/final_project/models/tfidf_vectorizer_3_labels.pkl')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba = model.predict_proba(X_test_tfidf)\n",
    "print(\"Predicted probabilities:\\n\", y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed Sentence America’s misunderstood border crisis, in 8 charts\n",
      "Predicted Class: ['right']\n",
      "Predicted Probabilities:\n",
      "left:  0.4121\n",
      "right:  0.5879\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib  # for saving/loading models\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "model = joblib.load('/Users/bryce/Desktop/INLS697/INLS697_proj/models/logistic_regression_model_2_labels.pkl')  # Adjust the filename as necessary\n",
    "vectorizer = joblib.load('/Users/bryce/Desktop/INLS697/INLS697_proj/models/tfidf_vectorizer_2_labels.pkl')  # Adjust the filename as necessary\n",
    "\n",
    "# Function to clean the text (should be the same as used during training)\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# New sentence for testing\n",
    "new_sentence = \"America’s misunderstood border crisis, in 8 charts\"\n",
    "cleaned_sentence = clean_text(new_sentence)\n",
    "\n",
    "# Vectorize the sentence\n",
    "vectorized_sentence = vectorizer.transform([cleaned_sentence])\n",
    "\n",
    "# Predict the class\n",
    "predicted_class = model.predict(vectorized_sentence)\n",
    "predicted_proba = model.predict_proba(vectorized_sentence)\n",
    "\n",
    "class_labels = model.classes_\n",
    "\n",
    "# Display Predicted Class and Probabilities with Labels\n",
    "print(f\"Analyzed Sentence {new_sentence}\")\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\")\n",
    "for label, proba in zip(class_labels, predicted_proba[0]):\n",
    "    print(f\"{label}: {proba: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id predicted_label\n",
      "0   0           right\n",
      "1   1           right\n",
      "2   2           right\n",
      "3   3           right\n",
      "4   4           right\n",
      "5   5           right\n",
      "6   6           right\n",
      "7   7           right\n",
      "8   8           right\n",
      "9   9           right\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "model = joblib.load('/Users/bryce/Desktop/INLS690/final_project/models/logistic_regression_model_2_labels.pkl')\n",
    "vectorizer = joblib.load('/Users/bryce/Desktop/INLS690/final_project/models/tfidf_vectorizer_2_labels.pkl')\n",
    "\n",
    "# Load the test dataset\n",
    "test_df = pd.read_csv('/Users/bryce/Desktop/INLS690/Final_project/test.csv')  # Update the path to your test set\n",
    "\n",
    "# Transform the test set using the loaded vectorizer\n",
    "X_test_tfidf = vectorizer.transform(test_df['content'])\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test = model.predict(X_test_tfidf)\n",
    "\n",
    "# Create a DataFrame with ID and predicted labels\n",
    "predicted_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'predicted_label': y_pred_test\n",
    "})\n",
    "\n",
    "# Save or print the result\n",
    "print(predicted_df)\n",
    "\n",
    "# If you want to save to a new CSV file\n",
    "predicted_df.to_csv('/Users/bryce/Desktop/INLS690/final_project/test_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec approach\n",
    "\n",
    "Better approach than TF-IDF because it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean up text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/bryce/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stop words if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    \n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Rejoin filtered words back into a string\n",
    "    text = ' '.join(filtered_words)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5657894736842105\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        left       0.71      0.52      0.60        96\n",
      "       right       0.44      0.64      0.52        56\n",
      "\n",
      "    accuracy                           0.57       152\n",
      "   macro avg       0.58      0.58      0.56       152\n",
      "weighted avg       0.61      0.57      0.57       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Function to tokenize and clean a document\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Updated function to tokenize, clean, and remove stop words\n",
    "def clean_and_tokenize(sentence):\n",
    "    words = gensim.utils.simple_preprocess(sentence)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "# Function to create a mean vector for a document based on Word2Vec model\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # Remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0) if len(doc) > 0 else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('/Users/bryce/Desktop/INLS690/final_project/combined_dataset_2-labels.csv')\n",
    "\n",
    "# Split original text and processed text\n",
    "X_original = df['cleaned_content']  # Original text\n",
    "X_processed = X_original.apply(clean_and_tokenize)  # Processed text for model input\n",
    "y = df['political_label']\n",
    "\n",
    "# Train Word2Vec model\n",
    "# sg = 1 is Skip-gram; sg = 0 is CBOW (continuous bag of words)\n",
    "vector_size = 500\n",
    "window_size = 4\n",
    "sq_type = 0\n",
    "word2vec_model = gensim.models.Word2Vec(sentences=X_processed, vector_size=vector_size, window=window_size, min_count=3, workers=4, sg = sq_type)\n",
    "\n",
    "# Generate document vectors\n",
    "X_vectors = np.array([document_vector(word2vec_model, doc) for doc in X_processed])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, X_train_original, X_test_original, y_train, y_test = train_test_split(X_vectors, X_original, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Initialize and train Logistic Regression model\n",
    "logistic_model = LogisticRegression(C=10, max_iter=1000, class_weight='balanced')\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(logistic_model, '/Users/bryce/Desktop/INLS690/final_project/models/logistic_regression_model_w2v.pkl')\n",
    "word2vec_model.save('/Users/bryce/Desktop/INLS690/final_project/models/word2vec_model.model')\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to predict the class and probabilities for a single sentence\n",
    "def predict_single_sentence(sentence, word2vec_model, logistic_model):\n",
    "    tokenized_sentence = clean_and_tokenize(sentence)\n",
    "    sentence_vector = document_vector(word2vec_model, tokenized_sentence).reshape(1, -1)\n",
    "    predicted_class = logistic_model.predict(sentence_vector)\n",
    "    predicted_proba = logistic_model.predict_proba(sentence_vector)\n",
    "    return predicted_class[0], predicted_proba[0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id predicted_label\n",
      "0   10           right\n",
      "1   11            left\n",
      "2   12           right\n",
      "3   13           right\n",
      "4   14           right\n",
      "5   15           right\n",
      "6   16           right\n",
      "7   17           right\n",
      "8   18           right\n",
      "9   19            left\n",
      "10  20            left\n",
      "11  21           right\n",
      "12  22           right\n",
      "13  23           right\n",
      "14  24           right\n",
      "15  25           right\n",
      "16  26            left\n",
      "17  27           right\n",
      "18  28            left\n",
      "19  29           right\n",
      "20  30            left\n",
      "21  31           right\n",
      "22  32            left\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "import joblib\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the trained Word2Vec and Logistic Regression models\n",
    "logistic_model_saved = joblib.load('/Users/bryce/Desktop/INLS690/final_project/models/logistic_regression_model_w2v.pkl')\n",
    "word2vec_model_saved = gensim.models.Word2Vec.load('/Users/bryce/Desktop/INLS690/final_project/models/word2vec_model.model')\n",
    "\n",
    "# Function to clean and tokenize a document (make sure to define the stop_words as before)\n",
    "def clean_and_tokenize(sentence):\n",
    "    words = gensim.utils.simple_preprocess(sentence)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "# Function to create a mean vector for a document based on Word2Vec model\n",
    "def document_vector(word2vec_model_saved, doc):\n",
    "    doc = [word for word in doc if word in word2vec_model_saved.wv.key_to_index]\n",
    "    return np.mean(word2vec_model_saved.wv[doc], axis=0) if len(doc) > 0 else np.zeros(word2vec_model_saved.vector_size)\n",
    "\n",
    "# Load the test dataset\n",
    "test_df = pd.read_csv('/Users/bryce/Desktop/INLS690/Final_project/large_test_set.csv')  # Update the path to your test set\n",
    "\n",
    "# Process the test data\n",
    "X_test_processed = test_df['content'].apply(clean_and_tokenize)\n",
    "\n",
    "# Generate vectors for the test data\n",
    "X_test_vectors = np.array([document_vector(word2vec_model_saved, doc) for doc in X_test_processed])\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_test = logistic_model_saved.predict(X_test_vectors)\n",
    "\n",
    "# Create a DataFrame with ID and predicted labels\n",
    "predicted_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'predicted_label': y_pred_test\n",
    "})\n",
    "\n",
    "# Save or print the result\n",
    "print(predicted_df)\n",
    "\n",
    "# Optionally, save to a new CSV file\n",
    "predicted_df.to_csv('/Users/bryce/Desktop/INLS690/final_project/test_predictions_w2v.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_saved = joblib.load('/Users/bryce/Desktop/INLS690/final_project/models/logistic_regression_model_w2v.pkl')\n",
    "\n",
    "word2vec_model_saved = gensim.models.Word2Vec.load('/Users/bryce/Desktop/INLS690/final_project/models/word2vec_model.model')\n",
    "\n",
    "def predict_single_sentence_from_saved_model(sentence, word2vec_model_saved, logistic_model_saved):\n",
    "    tokenized_sentence = clean_and_tokenize(sentence)\n",
    "    sentence_vector = document_vector(word2vec_model_saved, tokenized_sentence).reshape(1, -1)\n",
    "    predicted_class = logistic_model_saved.predict(sentence_vector)\n",
    "    predicted_proba = logistic_model_saved.predict_proba(sentence_vector)\n",
    "    return predicted_class[0], predicted_proba[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Right Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: right\n",
      "Predicted Probabilities: [0.4170388 0.5829612]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \" The climate change agenda is a hoax, and we need to declare independence. The reality is the anti-carbon agenda acts as a wet blanket on our economy.\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: right\n",
      "Predicted Probabilities: [0.3665513 0.6334487]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Withdrew from the unfair, one-sided Paris Climate Agreement.\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: right\n",
      "Predicted Probabilities: [0.18128166 0.81871834]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"It's argued that climate change isn't about saving the earth but about controlling people, and that there's a dislike for the earth and nature at play.\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: right\n",
      "Predicted Probabilities: [0.09919109 0.90080891]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"And when I see these people talking about global warming, where the ocean will rise by a 100th of an inch over the next 350 years, where it's going to get a little bit warmer or a little bit cooler, they don't know. You know, they talk to. We used to be global warming. They don't talk about it as much, though. No, they don't talk? No, they call or went into hiding or something. No, now they call it climate change because they said it's going to get warmer. It was getting colder, then it was going to get colder. It's getting warmer. You know, they used to say global cooling because they thought the world was going to freeze. That was in the 1920s, I think. Global cooling. Then it went to global warming, but that wasn't working, so now they go to climate change because that covers everything. Your real global warming would be nuclear global warming. That's a warming that will take seconds, and that's a warming that will melt granite. You know what granite is? It's a very powerful, very hard stone. If you take a look at Hiroshima, or Hiroshima, as a lot of people call it, Nagasaki, where they used nuclear in a very primitive form, it actually took granite, large areas of granite, and melted it. And now it's like an ice skating rink. It melted into virtual water, and now when it hardened, it was absolutely stone cold level. It melted Granite. You could hit granite with a blowtorch and it won't even do anything to it. So you're talking about a level of power, a level of heat, a level of destruction. Nobody talks about that. They talk about global warming. It's sick. And we have to get rid of nuclear weapons. You know, one of the things I was going to do, and I would have done, is the denouking of everything\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more christian approach to climate change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: right\n",
      "Predicted Probabilities: [0.48832655 0.51167345]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"good morning TikTok how are you today I'm pretty good laundry is going in the background I'm getting ready to do another art project here in a minute but first I thought I'd get on here and wrinkle some feathers just by putting a thought out there into the World and this message is for people WHO profess the Faith in Jesus christ and believe in god if you don't feel free to listen but it's not directed at you for those people WHO feel they are Christian and also believe in global climate crisis I'm gonna need you to check back in with god and have a conversation because last I believed god was omnipotent and god created everything this very Earth in fact and the idea that the god WHO created everything was somehow insufficient in his thought process and did not provide an Earth with enough resources for the number of lives he put on it it's mind boggling that you think that he or whatever you want it to be god god just kind of skipped out on that one and therefore you you you and all your other humans will manage the Earth better than the god WHO created it y'all come on get off yourself righteous stuff and start thinking realistically you cannot control the Earth nobody can and you are not smarter than the god WHO created it I'm just saying if you're a Christian and you believe in global climate crisis there's not a checks and balances up there there's not cause it makes no logical sense and that's where i i live in logic there's no logic and it is not Faith based because if you have Faith in god you believe that he provided and it's there for US to take you wanna know who's stopping US other humans and oh by the way last question and this has nothing to do with christianity why do the oil companies get to charge US for the oil they take out of the ground I get that they get to charge US for the processing of it but the oil itself that belongs to all of US we are inheritance of that why do they get to charge US for something that belongs to US start thinking about the Earth as your belonging becaUSe you are an inheritance of what god provided\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: left\n",
      "Predicted Probabilities: [0.75684347 0.24315653]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"And we have seen, around our country, where communities have been choked by drought, have been washed out by floods, and decimated by hurricanes.  Here in Baltimore, you have seen your skies darkened by wildfire smoke.  And you have seen the waters of the Chesapeake Bay rise, threatening homes and businesses that have stood for generations.\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: left\n",
      "Predicted Probabilities: [0.58362119 0.41637881]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Hello, my name is Olivia Colwine, and I want to extend a huge thank you on behalf of the fossil fuel industries for your support this year. People like you have invested billions of pounds into our gas and oil businesses. The funds from your pensions have enabled us to dig, drill, and impact the planet more than ever before. We've even constructed some wind turbines to appease environmental activists. Every bit of your investments contributes significantly. As a result, while global temperatures may rise slightly, our profits are significantly increasing, all thanks to your contributions. To ensure a profitable future for us, please continue to direct your pensions our way. You know the drill. Oh, fucking hell. Okay, start skin. Start skin. Yes!\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: left\n",
      "Predicted Probabilities: [0.62305211 0.37694789]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Why is the COP28 climate change summit being used to strike fossil fuel deals? According to BBC-published documents, the United Arab Emirates planned to use the COP28 meetings to promote deals for its national gas and oil companies. The documents suggest discussion points for fossil fuel deals with 15 nations, including China. However, COP28 officials rejected these implications, stating that the president is solely focused on business related to COP and achieving ambitious, transformative climate outcomes. Yet, the emergence of such allegations at a conference like COP28, which can be seen as performative, is not surprising.\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: left\n",
      "Predicted Probabilities: [0.58053225 0.41946775]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I attended a funeral recently, which was held in a church. It's been a long time since I've been inside a church, but I've noticed that at most church funerals, especially in the South, the pastor often discusses Jesus and the message of Christianity. This particular service had a recurring theme: the world is falling apart and Jesus is the only hope. The interpretation seemed to be that the world is breaking down according to their understanding of scripture, leading to an epiphany for me. It struck me why many Christians might not be concerned about climate change. If the belief is that the world is deteriorating and heading towards an apocalypse, then striving to make the world a better place might seem futile. If anything, this belief could lead to a desire for the world to deteriorate faster, as it would hasten the return of Jesus and the subsequent journey to heaven. This perspective, when analyzed, appears incredibly selfish. It made me think about the societal and civilizational impact of such beliefs and where that places someone on the spectrum of human civilization. It's a thought-provoking realization about the potential implications of certain religious beliefs on environmental concerns. I hope this perspective encourages introspection, especially among Christians, regarding the broader implications of these beliefs.\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: right\n",
      "Predicted Probabilities: [0.29294134 0.70705866]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Our government has done more to fight climate change than any government in Canadian history. And that is only appropriate. You know, I began my remarks by referring to the forest fires here in Quebec. Uh, yesterday, uh, in Toronto, there was so much smog. Uh, not smogs, so much smoke from the forest fires that Toronto was one of the cities with the poorest air quality in the world. A climate change is upon us. It is a crisis. And the right thing to do is what our government is doing, um, which is to put a price on pollution. We have done that, and we've done that with the price on pollution. We've done that with the clean fuel standards and at the same time to support the innovative Canadian companies, whoever both how important that work in building the clean economy is, um, and that, you know, we, as a country, we can do it. You know, it is very easy to be really, uh, frightened by climate change, and we should be. Um, it is an existential challenge. But I think the response to that needs to be to do what we're doing, which is to invest in Canada and Canadians to have real faith and confidence in people like the brilliant engineers and computer programmers, uh, and innovators who are here. But about the pure regulations, companies shouldn't pass it. One question. 1. What? You say you should pay more? I've given my answer. Thanks. I'm so sorry.\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: left\n",
      "Predicted Probabilities: [0.89612507 0.10387493]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"c\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_test and y_test are your test datasets\n",
    "predictions = logistic_model.predict(X_test)\n",
    "probabilities = logistic_model.predict_proba(X_test)\n",
    "\n",
    "# Create a DataFrame for analysis\n",
    "error_analysis_df = pd.DataFrame({\n",
    "    'Text': X_test_original,  # original text of the test set\n",
    "    'True_Label': y_test,\n",
    "    'Predicted_Label': predictions,\n",
    "    'Predicted_Probability': probabilities.max(axis=1)\n",
    "})\n",
    "incorrect_predictions = error_analysis_df[error_analysis_df['True_Label'] != error_analysis_df['Predicted_Label']]\n",
    "\n",
    "print(incorrect_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In class example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: left\n",
      "Predicted Probabilities: [0.58053225 0.41946775]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I attended a funeral recently, which was held in a church. It's been a long time since I've been inside a church, but I've noticed that at most church funerals, especially in the South, the pastor often discusses Jesus and the message of Christianity. This particular service had a recurring theme: the world is falling apart and Jesus is the only hope. The interpretation seemed to be that the world is breaking down according to their understanding of scripture, leading to an epiphany for me. It struck me why many Christians might not be concerned about climate change. If the belief is that the world is deteriorating and heading towards an apocalypse, then striving to make the world a better place might seem futile. If anything, this belief could lead to a desire for the world to deteriorate faster, as it would hasten the return of Jesus and the subsequent journey to heaven. This perspective, when analyzed, appears incredibly selfish. It made me think about the societal and civilizational impact of such beliefs and where that places someone on the spectrum of human civilization. It's a thought-provoking realization about the potential implications of certain religious beliefs on environmental concerns. I hope this perspective encourages introspection, especially among Christians, regarding the broader implications of these beliefs.\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: right\n",
      "Predicted Probabilities: [0.32477443 0.67522557]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"good morning TikTok how are you today I'm pretty good laundry is going in the background I'm getting ready to do another art project here in a minute but first I thought I'd get on here and wrinkle some feathers just by putting a thought out there into the World and this message is for people WHO profess the Faith in Jesus christ and believe in god if you don't feel free to listen but it's not directed at you for those people WHO feel they are Christian and also believe in global climate crisis I'm gonna need you to check back in with god and have a conversation because last I believed god was omnipotent and god created everything this very Earth in fact and the idea that the god WHO created everything was somehow insufficient in his thought process and did not provide an Earth with enough resources for the number of lives he put on it it's mind boggling that you think that he or whatever you want it to be god god just kind of skipped out on that one and therefore you you you and all your other humans will manage the Earth better than the god WHO created it y'all come on get off yourself righteous stuff and start thinking realistically you cannot control the Earth nobody can and you are not smarter than the god WHO created it I'm just saying if you're a Christian and you believe in global climate crisis there's not a checks and balances up there there's not cause it makes no logical sense and that's where i i live in logic there's no logic and it is not Faith based because if you have Faith in god you believe that he provided and it's there for US to take you wanna know who's stopping US other humans and oh by the way last question and this has nothing to do with christianity why do the oil companies get to charge US for the oil they take out of the ground I get that they get to charge US for the processing of it but the oil itself that belongs to all of US we are inheritance of that why do they get to charge US for something that belongs to US start thinking about the Earth as your belonging becaUSe you are an inheritance of what god provided\"\n",
    "cleaned_sentence = clean_text(test_sentence)\n",
    "predicted_class, predicted_proba = predict_single_sentence_from_saved_model(cleaned_sentence, word2vec_model_saved, logistic_model_saved)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Predicted Probabilities:\", predicted_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
